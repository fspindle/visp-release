@Article{Tsai89a,
  author =	 {Tsai, R. and Lenz, R.},
  title =	 {A New Technique for Fully Autonomous and Efficient
                  {3{D}} Robotics Hand/Eye Calibration},
  journal =	 {IEEE Trans. on Robotics and Automation},
  year =	 1989,
  volume =	 5,
  number =	 3,
  pages =	 {345-358},
  month =	 jun
}

@Article{Lowe92a,
  author =	 {Lowe, D.G.},
  title =	 {Robust Model-based motion tracking trough the
                  integration of search and estimation},
  journal =	 {Int. Journal of Computer Vision},
  year =	 1992,
  volume =	 8,
  number =	 2,
  pages =	 {113-122},
  keyword =	 {tracking and cad and pose}
}

@PhdThesis{TheseMalis,
  author =	 {Malis, E.},
x-advisor = {Chaumette, F.},
  title =	 {Contributions à la modélisation et à la commande en
                  asservissement visuel},
  school =	 {Université de Rennes 1, Mention traitement du signal
                  et télécommunications},
  keywords =	 {Visual Servoing},
  year =	 1998,
  month =	 nov,
  abstract =	 {Our work is concerned with robotics and vision, and
                  more precisely visual servoing. It consists in the
                  design of methods that do not need the model of the
                  observed objects or a precise calibration of the
                  system. First, the problem of the Euclidean
                  reconstruction (up to a scale factor), from two
                  images of a unknown static object, has been
                  studied. It has been highlighted that the best
                  linear solution for a robust reconstruction of the
                  camera displacement is to use an homography
                  matrix. Thus, an algorithm for the linear estimation
                  of this matrix has been proposed. Then, two new
                  visual servoing schemes, based on the partial
                  Euclidean reconstruction, are proposed. The
                  closed-loop system is analyzed in order to obtain
                  the robustness domain of a proportional control law
                  with respect to the system calibration
                  errors. Later, it has been shown that, thanks to the
                  decoupled structure of the considered systems, it is
                  possible to considerably increase the robustness
                  domain with an adaptive control law. The new methods
                  have been tested on a Cartesian robot and on a
                  redundant robot, and then compared to the classic
                  ones. The obtained results confirm the improvement
                  in the stability of our methods. Finally, the visual
                  servoing techniques have been extended to the use of
                  several cameras observing different parts of the
                  scene. The multi-camera visual servoing has been
                  designed as a part of the task function
                  approach. The particular choice of the task function
                  allows us to simplify the design of the control law
                  and the stability analysis. In the end, a
                  positioning task of a cumbersome object has been
                  realized using two cameras mounted on a manipulator
                  robot.},
  pdf =
                  {http://www.irisa.fr/lagadic/pdf/1998_these_malis.pdf},
  urltransp =
                  {http://www.irisa.fr/lagadic/pdf/1998_these_malis_transp.pdf}
}

@article{Malis00b,
  author =	 {Malis, E. and Chaumette, F. and Boudet, S.},
  title =	 {2 1/2 {D} Visual Servoing with Respect to Unknown
                  Objects Through a New Estimation Scheme of Camera
                  Displacement},
  journal =	 {Int. Journal of Computer Vision},
  volume =	 37,
  year =	 2000,
  number =	 1,
  month =	 jun,
  pages =	 {79-97}
}

@Article{Dementhon95,
  author =	 {Dementhon, D. and Davis, L.},
  title =	 {Model-Based Object Pose in 25 Lines of Codes},
  journal =	 {Int. J. of Computer Vision},
  year =	 1995,
  volume =	 15,
  number =	 {1-2},
  pages =	 {123--141},
  keyword =	 {pose}
}

@InProceedings{Marchand02c,
  author =	 {Marchand, E. and Chaumette, F.},
  title =	 {Virtual Visual Servoing: a framework for real-time
                  augmented reality},
  booktitle =	 {EUROGRAPHICS'02 Conf. Proceeding},
  pages =	 {289--298},
  year =	 2002,
  volume =	 {21(3)},
  editor =	 {Drettakis, G. and Seidel, H.-P.},
  series =	 {Computer Graphics Forum},
  address =	 {Saarebr\"ucken, Germany},
  month =	 sep
}

@Article{Chaumette04a,
  author =	 {Chaumette, F.},
  title =	 {Image moments: a general and useful set of features
                  for visual servoing},
  journal =	 {IEEE Trans. on Robotics},
  year =	 2004,
  month =	 aug,
  number =	 4,
  volume =	 20,
  pages =	 {713-723},
  abstract =	 {In this paper, we determine the analytical form of
                  the interaction matrix related to any moment that
                  can be computed from segmented images. The
                  derivation method we present is based on Green's
                  theorem. We apply this general result to classical
                  geometrical primitives. We then consider using
                  moments in image-based visual servoing. For that, we
                  select six combinations of moments to control the
                  six degrees of freedom of the system. These features
                  are particularly adequate if we consider a planar
                  object and the configurations such that the object
                  and camera planes are parallel at the desired
                  position. The experimental results we present show
                  that a correct behavior of the system is obtained if
                  we consider either a simple symmetrical object or a
                  planar object with complex and unknown shape.},
  pdf =
                  {http://www.irisa.fr/lagadic/pdf/2004_itro_chaumette.pdf},
  keyword =	 {visual servoing, robotics, modeling}
}

@article{Marchand05b,
   Author = {Marchand, E. and Spindler, F. and Chaumette, F.},
   Title = {ViSP for visual servoing: a generic software platform with a wide class of robot control skills},
   Journal = {IEEE Robotics and Automation Magazine},
   Volume = {    12},
   Number = {4},
   Pages = {40--52},
   Publisher = {IEEE},
   Month = {December},
   Year = {2005}
} 

@article{Tahri05z,
   Author = {Tahri, O. and Chaumette, F.},
   Title = {Point-based and region-based image moments for visual servoing of planar objects},
   Journal = {IEEE Trans. on Robotics},
   Volume = {    21},
   Number = {6},
   Pages = {1116--1127},
   Publisher = {IEEE},
   Month = {December},
   Year = {2005}
} 

@Article{Comport06b,
  author =	 {Comport, A.I. and Marchand, E. and Pressigout,
                  M. and F. Chaumette},
  title =	 {Real-time markerless tracking for augmented reality:
                  the virtual visual servoing framework},
  journal =	 {IEEE Trans. on Visualization and Computer Graphics},
  year =	 2006,
  month =	 jul,
  number =	 4,
  volume =	 12,
  doi =		 {http://dx.doi.org/10.1109/TVCG.2006.78},
  pages =	 {615-628},
  pdf =
                  {http://www.irisa.fr/lagadic/pdf/2006_ieee_tvcg_comport.pdf},
  abstract =	 { Tracking is a very important research subject in a
                  real-time augmented reality context. The main
                  requirements for trackers are high accuracy and
                  little latency at a reasonable cost. In order to
                  address these issues, a real-time, robust and
                  efficient 3D model-based tracking algorithm is
                  proposed for a 'video see through' monocular vision
                  system. The tracking of objects in the scene amounts
                  to calculating the pose between the camera and the
                  objects.  Virtual objects can then be projected into
                  the scene using the pose. Here, non-linear pose
                  estimation is formulated by means of a virtual
                  visual servoing approach. In this context, the
                  derivation of point-to-curves interaction matrices
                  are given for different 3D geometrical primitives
                  including straight lines, circles, cylinders and
                  spheres. A local moving edges tracker is used in
                  order to provide real-time tracking of points normal
                  to the object contours.  Robustness is obtained by
                  integrating a M-estimator into the visual control
                  law via an iteratively re-weighted least squares
                  implementation. This approach is then extended to
                  address the 3D model-free augmented reality problem.
                  The method presented in this paper has been
                  validated on several complex image sequences
                  including outdoor environments.  Results show the
                  method to be robust to occlusion, changes in
                  illumination and miss-tracking.}
}

@article{Chaumette06a,
   Author = {Chaumette, F. and Hutchinson, S.},
   Title = {Visual servo control, Part I: Basic approaches},
   Journal = {IEEE Robotics and Automation Magazine},
   Volume = {    13},
   Number = {4},
   Pages = {82--90},
   Month = {December},
   Year = {2006}
} 

@article{Chaumette07a,
   Author = {Chaumette, F. and Hutchinson, S.},
   Title = {Visual servo control, Part II: Advanced approaches},
   Journal = {IEEE Robotics and Automation Magazine},
   Volume = {    14},
   Number = {1},
   Pages = {109--118},
   Month = {March},
   Year = {2007}
} 

@InProceedings{Corke09a,
   Author = {Corke, P. and Spindler, F. and Chaumette, F.},
   Title = {Combining Cartesian and cylindrical coordinates in IBVS},
   BookTitle = {IEEE Int. Conf. on Intelligent Robots and Systems, IROS'09},
   Pages = {5962--5967},
   Address = {St Louis, USA},
   Month = {October},
   Year = {2009}
} 